{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng_to_Python_v_FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtqFgsJealQJ"
      },
      "source": [
        "pip install sacrebleu==1.2.11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgTxHeAvl3Er"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import spacy\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "from py_tokenizer import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwMMe5CQCU5g"
      },
      "source": [
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpNTE2GhCY2V"
      },
      "source": [
        "#!python -m spacy download en\n",
        "spacy_en = spacy.load('en')\n",
        "spacy_py = spacy.load('en')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzDSSKOHhNX6"
      },
      "source": [
        "def tokenize_en(text):\n",
        "\n",
        "  \"\"\"\n",
        "  Tokenizes English text from a string into a list of strings\n",
        "  \"\"\"\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_py(text):\n",
        "  \"\"\"\n",
        "    Tokenizes Python Program from a string into a list of strings\n",
        "    \"\"\"\n",
        "  temp = \" \".join(tokenize_python(text))\n",
        "  return [tok.text for tok in spacy_py.tokenizer(temp)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCGN0pCEwXIV"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns_ApRSdzQ6t",
        "outputId": "bc6e7eb0-c8f6-4542-bc5e-5c5b7ff646a5"
      },
      "source": [
        "fundict ={}\n",
        "with open('Cleaned_Eng_Python_Data.txt', 'r') as fR:\n",
        "\n",
        "    #with open('fileWithoutComments.txt', 'w', encoding='utf-8') as fw:\n",
        "    for i in fR.readlines():\n",
        "\n",
        "        # print(i, end='')\n",
        "        # print(type(i))\n",
        "        if i.startswith('#') and  ('write' in i.lower() or 'python' in i.lower() or \\\n",
        "            'program' in i.lower() or 'function' in i.lower() or 'generate' in i.lower() or \\\n",
        "            'code' in i.lower() or 'given' in i.lower() or 'find' in i.lower() or 'calculate' in i.lower() or\\\n",
        "            'class' in i.lower() or 'define' in i.lower() or 'check' in i.lower() or 'compute' in i.lower() \\\n",
        "            or 'script' in i.lower() or 'calculate' in i.lower()):\n",
        "            # print(i)\n",
        "            key = i[1:]\n",
        "            \n",
        "\n",
        "            fundict[key]=''\n",
        "            continue\n",
        "        else:\n",
        "            fundict[key]= fundict[key] + i\n",
        "\n",
        "print(len(fundict))   "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb5M0Ipszxs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba72974-035c-480d-f12e-5ef28b6ef067"
      },
      "source": [
        "src = []\n",
        "trg = []\n",
        "\n",
        "src_len = []\n",
        "trg_len = []\n",
        "\n",
        "for k,v in fundict.items():\n",
        "  if len(k)<300 and len(v)<400:\n",
        "    src.append(k)\n",
        "    trg.append(v)\n",
        "    src_len.append(len(k))\n",
        "    trg_len.append(len(v))\n",
        "    \n",
        "print(f'Key_len:{max(src_len)} and Value: {max(trg_len)}, english sentence:{len(src)} and python code:{len(trg)}')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key_len:257 and Value: 399, english sentence:3071 and python code:3071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGqIUNv91hw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92277400-0166-4c4a-898d-dcbe5e49e9d0"
      },
      "source": [
        "src_len=[]\n",
        "trg_len =[]\n",
        "for i in range(len(src)):\n",
        "  src_len.append(len(src[i]))\n",
        "  trg_len.append(len(trg[i]))\n",
        "\n",
        "print(max(src_len), max(trg_len))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "257 399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beDtDuj95kuL"
      },
      "source": [
        "raw_data = {'English' : [line for line in src], 'Python': [line for line in trg]}\n",
        "df = pd.DataFrame(raw_data, columns=[\"English\", \"Python\"])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDk5uiec-KBv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# create train and validation set \n",
        "train, val = train_test_split(df, test_size=0.1)\n",
        "#train, val, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
        "\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "val.to_csv(\"val.csv\", index=False)\n",
        "#test.to_csv(\"test.csv\", index=False)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60O0YZ8eCrLd"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_py, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = False, \n",
        "            batch_first = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtxAxA7M_omT"
      },
      "source": [
        "data_fields = [('English', SRC), ('Python', TRG)]\n",
        "train,val = TabularDataset.splits(path='./', train='train.csv', validation='val.csv', format='csv', fields=data_fields)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4-1dVm5tnff"
      },
      "source": [
        "SRC.build_vocab(train)\n",
        "TRG.build_vocab(train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY9wlAUiB2WG",
        "outputId": "51144ca1-ea19-428f-ce35-a1b931585b9e"
      },
      "source": [
        "print(f\"Number of training examples: {len(train.examples)}\")\n",
        "print(f\"Number of validation examples: {len(val.examples)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 2764\n",
            "Number of validation examples: 309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAXNIzyvDJqa",
        "outputId": "f10c3a63-81c5-440c-90ce-b1a1d9a23af2"
      },
      "source": [
        "print(vars(train.examples[1]))\n",
        "print(vars(val.examples[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'English': [' ', 'write', 'a', 'python', 'function', 'to', 'extract', 'odd', 'length', 'words', 'in', 'string'], 'Python': ['def', 'findoddlenthwords', '(', 'test_str', ')', ':', 'NEW_LINE', 'INDENT', 'res', '=', '[', ']', 'NEW_LINE', 'for', 'ele', 'in', 'test_str', '.', 'split', '(', ')', ':', 'NEW_LINE', 'INDENT', 'if', 'len', '(', 'ele', ')', '%', '2', ':', 'NEW_LINE', 'INDENT', 'res', '.', 'append', '(', 'ele', ')', 'NEW_LINE', 'DEDENT', 'DEDENT', 'return', 'res', 'NEW_LINE', 'DEDENT']}\n",
            "{'English': [' ', 'write', 'a', 'python', 'program', 'to', 'typecast', 'given', 'input', 'to', 'float'], 'Python': ['num', '=', 'float', '(', 'input', '(', '\"', 'Input', '▁', 'a', '▁', 'value', ':', '▁', '\"', ')', ')', 'NEW_LINE', 'print', '(', 'num', ')', 'NEW_LINE']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8P8T6jpwpNa",
        "outputId": "d72e9fcd-c34b-47e5-9f57-8a5fc38ead72"
      },
      "source": [
        "n=7\n",
        "print(' '.join([str(elem) for elem in vars(train.examples[n])['English'][1:]]))\n",
        "print(detokenize_python(vars(train.examples[n])['Python']))\n",
        "print(' '.join([str(elem) for elem in vars(val.examples[n])['English'][1:]]))\n",
        "#convert_format(vars(val.examples[1])['Python'])\n",
        "print(detokenize_python(vars(val.examples[n])['Python']))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "write a python program to input a number n and print an inverted star pattern of the desired size .\n",
            "n = int ( input ( \"Enter number of rows: \" ) )\n",
            "for i in range ( n , 0 , - 1 ) :\n",
            "    print ( ( n - i ) * ' ' + i * '*' )\n",
            "\n",
            "write a program to write a string in a file\n",
            "filename = 'file1.txt'\n",
            "string = \"programming in \\n python\"\n",
            "f1 = open ( filename , 'w' )\n",
            "f1.write ( string )\n",
            "f1.close ( )\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOaChRG5Y0Yu"
      },
      "source": [
        "# print(' '.join([str(elem) for elem in vars(train.examples[1])['English']]))\n",
        "# print(' '.join([str(elem) for elem in vars(train.examples[1])['Python']]))\n",
        "# print(' '.join([str(elem) for elem in vars(val.examples[1])['English']]))\n",
        "\n",
        "# print(' '.join([str(elem) for elem in vars(val.examples[1])['Python']]))\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCe5w8J8IPkT",
        "outputId": "f817cb6e-b713-4d07-f11c-0277ef3fb2cd"
      },
      "source": [
        "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (de) vocabulary: 1869\n",
            "Unique tokens in target (en) vocabulary: 4266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XONz6UrCwuh",
        "outputId": "ff19f2b6-2622-4f12-8db9-5650f5b151e8"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBtCv6sACyZ8"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits((train, val),sort_key=lambda x: len(x.English),\\\n",
        "                                                       sort_within_batch=False, batch_size = BATCH_SIZE, \\\n",
        "                                                       device = device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE6JimgOCz-w"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 260):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        #print(f'batch_size:{batch_size}')\n",
        "        src_len = src.shape[1]\n",
        "        #print(f'src_len:{src_len}')\n",
        "\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        \n",
        "\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            \n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "\n",
        "        #print('src layers created')  \n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        #print('going to return src') \n",
        "        return src"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LheiXWVFDEg"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZmeHfGhGzkN"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9w9xDUKL7LU"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWBMMF45MMNS"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 400):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        #print(f'target length:{trg_len}')\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMEr1IFUMxco"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udpPhQ2UN8oQ"
      },
      "source": [
        "10000\n",
        "11000\n",
        "11100\n",
        "11100\n",
        "11100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr3Mg8OGN6ul"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "        \n",
        "        #print(f'trg_pad_mask:{trg_pad_mask.is_cuda}, and trg_sub_mask: {trg_sub_mask.is_cuda} ')\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        #print(f'src_mask received')\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        #print(f'trg_mask received')\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        #print('enc_src done')\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zsZjSSWOSHc"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 512\n",
        "ENC_LAYERS = 6\n",
        "DEC_LAYERS = 6\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 1024\n",
        "DEC_PF_DIM = 1024\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYVZYDVcOUGK"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd0ePzj0OzLa",
        "outputId": "fb94eb89-4de3-466f-e2c6-3b9d2f6c5325"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 37,210,794 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmZ0hyo8O0vE"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRtAM9Y4O2N2"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEpApG3YO3ZE"
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Dy_wWrO46l"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycBBiEpuO6cG"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        \n",
        "        src = batch.English\n",
        "        #print(f'src:{src}')\n",
        "        trg = batch.Python\n",
        "        #print(f'trg:{trg}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #print(f'optimizer phase done')\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi3Ev8gaO79_"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.English\n",
        "            trg = batch.Python\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuB4JqQRO9Wg"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aax76Ie4O_Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b1db0a-f678-48d4-b858-50c2bfa9db24"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'Eng-to-Python-model.pt')\n",
        "        \n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 22s\n",
            "\tTrain Loss: 5.942 | Train PPL: 380.554\n",
            "\t Val. Loss: 4.898 |  Val. PPL: 133.968\n",
            "Epoch: 02 | Time: 0m 23s\n",
            "\tTrain Loss: 4.644 | Train PPL: 103.980\n",
            "\t Val. Loss: 4.119 |  Val. PPL:  61.521\n",
            "Epoch: 03 | Time: 0m 24s\n",
            "\tTrain Loss: 3.764 | Train PPL:  43.102\n",
            "\t Val. Loss: 3.392 |  Val. PPL:  29.738\n",
            "Epoch: 04 | Time: 0m 24s\n",
            "\tTrain Loss: 3.246 | Train PPL:  25.680\n",
            "\t Val. Loss: 3.073 |  Val. PPL:  21.598\n",
            "Epoch: 05 | Time: 0m 25s\n",
            "\tTrain Loss: 2.949 | Train PPL:  19.094\n",
            "\t Val. Loss: 2.854 |  Val. PPL:  17.357\n",
            "Epoch: 06 | Time: 0m 26s\n",
            "\tTrain Loss: 2.732 | Train PPL:  15.364\n",
            "\t Val. Loss: 2.677 |  Val. PPL:  14.536\n",
            "Epoch: 07 | Time: 0m 25s\n",
            "\tTrain Loss: 2.564 | Train PPL:  12.991\n",
            "\t Val. Loss: 2.540 |  Val. PPL:  12.678\n",
            "Epoch: 08 | Time: 0m 25s\n",
            "\tTrain Loss: 2.422 | Train PPL:  11.268\n",
            "\t Val. Loss: 2.435 |  Val. PPL:  11.412\n",
            "Epoch: 09 | Time: 0m 25s\n",
            "\tTrain Loss: 2.305 | Train PPL:  10.025\n",
            "\t Val. Loss: 2.352 |  Val. PPL:  10.506\n",
            "Epoch: 10 | Time: 0m 25s\n",
            "\tTrain Loss: 2.203 | Train PPL:   9.048\n",
            "\t Val. Loss: 2.270 |  Val. PPL:   9.675\n",
            "Epoch: 11 | Time: 0m 25s\n",
            "\tTrain Loss: 2.101 | Train PPL:   8.175\n",
            "\t Val. Loss: 2.206 |  Val. PPL:   9.076\n",
            "Epoch: 12 | Time: 0m 25s\n",
            "\tTrain Loss: 2.012 | Train PPL:   7.481\n",
            "\t Val. Loss: 2.150 |  Val. PPL:   8.581\n",
            "Epoch: 13 | Time: 0m 26s\n",
            "\tTrain Loss: 1.932 | Train PPL:   6.900\n",
            "\t Val. Loss: 2.101 |  Val. PPL:   8.175\n",
            "Epoch: 14 | Time: 0m 25s\n",
            "\tTrain Loss: 1.860 | Train PPL:   6.424\n",
            "\t Val. Loss: 2.064 |  Val. PPL:   7.878\n",
            "Epoch: 15 | Time: 0m 26s\n",
            "\tTrain Loss: 1.781 | Train PPL:   5.938\n",
            "\t Val. Loss: 2.014 |  Val. PPL:   7.497\n",
            "Epoch: 16 | Time: 0m 25s\n",
            "\tTrain Loss: 1.723 | Train PPL:   5.602\n",
            "\t Val. Loss: 1.974 |  Val. PPL:   7.201\n",
            "Epoch: 17 | Time: 0m 25s\n",
            "\tTrain Loss: 1.650 | Train PPL:   5.209\n",
            "\t Val. Loss: 1.950 |  Val. PPL:   7.027\n",
            "Epoch: 18 | Time: 0m 25s\n",
            "\tTrain Loss: 1.589 | Train PPL:   4.900\n",
            "\t Val. Loss: 1.921 |  Val. PPL:   6.830\n",
            "Epoch: 19 | Time: 0m 25s\n",
            "\tTrain Loss: 1.530 | Train PPL:   4.619\n",
            "\t Val. Loss: 1.891 |  Val. PPL:   6.625\n",
            "Epoch: 20 | Time: 0m 25s\n",
            "\tTrain Loss: 1.472 | Train PPL:   4.358\n",
            "\t Val. Loss: 1.879 |  Val. PPL:   6.548\n",
            "Epoch: 21 | Time: 0m 25s\n",
            "\tTrain Loss: 1.424 | Train PPL:   4.153\n",
            "\t Val. Loss: 1.853 |  Val. PPL:   6.379\n",
            "Epoch: 22 | Time: 0m 25s\n",
            "\tTrain Loss: 1.368 | Train PPL:   3.926\n",
            "\t Val. Loss: 1.837 |  Val. PPL:   6.279\n",
            "Epoch: 23 | Time: 0m 25s\n",
            "\tTrain Loss: 1.325 | Train PPL:   3.762\n",
            "\t Val. Loss: 1.811 |  Val. PPL:   6.118\n",
            "Epoch: 24 | Time: 0m 25s\n",
            "\tTrain Loss: 1.280 | Train PPL:   3.595\n",
            "\t Val. Loss: 1.792 |  Val. PPL:   6.002\n",
            "Epoch: 25 | Time: 0m 25s\n",
            "\tTrain Loss: 1.236 | Train PPL:   3.440\n",
            "\t Val. Loss: 1.788 |  Val. PPL:   5.977\n",
            "Epoch: 26 | Time: 0m 25s\n",
            "\tTrain Loss: 1.200 | Train PPL:   3.319\n",
            "\t Val. Loss: 1.771 |  Val. PPL:   5.877\n",
            "Epoch: 27 | Time: 0m 26s\n",
            "\tTrain Loss: 1.159 | Train PPL:   3.188\n",
            "\t Val. Loss: 1.766 |  Val. PPL:   5.846\n",
            "Epoch: 28 | Time: 0m 25s\n",
            "\tTrain Loss: 1.124 | Train PPL:   3.077\n",
            "\t Val. Loss: 1.764 |  Val. PPL:   5.836\n",
            "Epoch: 29 | Time: 0m 25s\n",
            "\tTrain Loss: 1.085 | Train PPL:   2.959\n",
            "\t Val. Loss: 1.754 |  Val. PPL:   5.779\n",
            "Epoch: 30 | Time: 0m 25s\n",
            "\tTrain Loss: 1.044 | Train PPL:   2.842\n",
            "\t Val. Loss: 1.724 |  Val. PPL:   5.604\n",
            "Epoch: 31 | Time: 0m 25s\n",
            "\tTrain Loss: 1.010 | Train PPL:   2.746\n",
            "\t Val. Loss: 1.713 |  Val. PPL:   5.545\n",
            "Epoch: 32 | Time: 0m 25s\n",
            "\tTrain Loss: 0.977 | Train PPL:   2.656\n",
            "\t Val. Loss: 1.729 |  Val. PPL:   5.638\n",
            "Epoch: 33 | Time: 0m 25s\n",
            "\tTrain Loss: 0.948 | Train PPL:   2.581\n",
            "\t Val. Loss: 1.710 |  Val. PPL:   5.531\n",
            "Epoch: 34 | Time: 0m 25s\n",
            "\tTrain Loss: 0.921 | Train PPL:   2.513\n",
            "\t Val. Loss: 1.711 |  Val. PPL:   5.534\n",
            "Epoch: 35 | Time: 0m 25s\n",
            "\tTrain Loss: 0.891 | Train PPL:   2.438\n",
            "\t Val. Loss: 1.701 |  Val. PPL:   5.480\n",
            "Epoch: 36 | Time: 0m 25s\n",
            "\tTrain Loss: 0.861 | Train PPL:   2.366\n",
            "\t Val. Loss: 1.705 |  Val. PPL:   5.500\n",
            "Epoch: 37 | Time: 0m 25s\n",
            "\tTrain Loss: 0.835 | Train PPL:   2.304\n",
            "\t Val. Loss: 1.705 |  Val. PPL:   5.502\n",
            "Epoch: 38 | Time: 0m 25s\n",
            "\tTrain Loss: 0.805 | Train PPL:   2.236\n",
            "\t Val. Loss: 1.700 |  Val. PPL:   5.473\n",
            "Epoch: 39 | Time: 0m 26s\n",
            "\tTrain Loss: 0.781 | Train PPL:   2.183\n",
            "\t Val. Loss: 1.689 |  Val. PPL:   5.416\n",
            "Epoch: 40 | Time: 0m 25s\n",
            "\tTrain Loss: 0.754 | Train PPL:   2.126\n",
            "\t Val. Loss: 1.697 |  Val. PPL:   5.455\n",
            "Epoch: 41 | Time: 0m 26s\n",
            "\tTrain Loss: 0.736 | Train PPL:   2.087\n",
            "\t Val. Loss: 1.698 |  Val. PPL:   5.462\n",
            "Epoch: 42 | Time: 0m 25s\n",
            "\tTrain Loss: 0.707 | Train PPL:   2.027\n",
            "\t Val. Loss: 1.703 |  Val. PPL:   5.490\n",
            "Epoch: 43 | Time: 0m 25s\n",
            "\tTrain Loss: 0.687 | Train PPL:   1.987\n",
            "\t Val. Loss: 1.689 |  Val. PPL:   5.414\n",
            "Epoch: 44 | Time: 0m 25s\n",
            "\tTrain Loss: 0.665 | Train PPL:   1.944\n",
            "\t Val. Loss: 1.724 |  Val. PPL:   5.606\n",
            "Epoch: 45 | Time: 0m 25s\n",
            "\tTrain Loss: 0.640 | Train PPL:   1.897\n",
            "\t Val. Loss: 1.703 |  Val. PPL:   5.490\n",
            "Epoch: 46 | Time: 0m 26s\n",
            "\tTrain Loss: 0.623 | Train PPL:   1.864\n",
            "\t Val. Loss: 1.696 |  Val. PPL:   5.455\n",
            "Epoch: 47 | Time: 0m 25s\n",
            "\tTrain Loss: 0.601 | Train PPL:   1.824\n",
            "\t Val. Loss: 1.700 |  Val. PPL:   5.477\n",
            "Epoch: 48 | Time: 0m 26s\n",
            "\tTrain Loss: 0.589 | Train PPL:   1.803\n",
            "\t Val. Loss: 1.700 |  Val. PPL:   5.471\n",
            "Epoch: 49 | Time: 0m 26s\n",
            "\tTrain Loss: 0.569 | Train PPL:   1.766\n",
            "\t Val. Loss: 1.718 |  Val. PPL:   5.572\n",
            "Epoch: 50 | Time: 0m 25s\n",
            "\tTrain Loss: 0.549 | Train PPL:   1.731\n",
            "\t Val. Loss: 1.720 |  Val. PPL:   5.582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3_aq7QTPBFc",
        "outputId": "e33defa6-08bb-4565-e7db-428817b9aa83"
      },
      "source": [
        "model.load_state_dict(torch.load('Eng-to-Python-model.pt'))\n",
        "\n",
        "#test_loss = evaluate(model, valid_iterator, criterion)\n",
        "#print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieIjql9uPKH1"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 500):\n",
        "    \n",
        "    model.eval()\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTBipndfPOlX"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
        "    \n",
        "    assert n_rows * n_cols == n_heads\n",
        "    \n",
        "    fig = plt.figure(figsize=(15,25))\n",
        "    \n",
        "    for i in range(n_heads):\n",
        "        \n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
        "        \n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                           rotation=45)\n",
        "        ax.set_yticklabels(['']+translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgtuHU-UPP02"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_py, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = False, \n",
        "            batch_first = True)\n",
        "\n",
        "data_fields = [('English', SRC), ('Python', TRG)]\n",
        "train,val = TabularDataset.splits(path='./', train='train.csv', validation='val.csv', format='csv', fields=data_fields)\n",
        "\n",
        "SRC.build_vocab(train, val)\n",
        "TRG.build_vocab(train, val)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hv0xTRNb5j7",
        "outputId": "c2105586-a888-4e46-bee4-229b7fd2488d"
      },
      "source": [
        "for i in range(1, 5):\n",
        "  src = vars(train.examples[i])['English']\n",
        "  print(f'Example {i}:\\n')\n",
        "  print(' '.join([str(elem) for elem in src]))\n",
        "  print('\\nActual Python Code')\n",
        "  trg = vars(train.examples[i])['Python']\n",
        "  print(detokenize_python(trg))\n",
        "  print('\\nPredicted Python Code')\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "  print(detokenize_python(translation))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example 1:\n",
            "\n",
            "  write a python function to extract odd length words in string\n",
            "\n",
            "Actual Python Code\n",
            "def findoddlenthwords ( test_str ) :\n",
            "    res = [ ]\n",
            "    for ele in test_str.split ( ) :\n",
            "        if len ( ele ) % 2 :\n",
            "            res.append ( ele )\n",
            "    return res\n",
            "\n",
            "\n",
            "Predicted Python Code\n",
            "def high ( List ) :\n",
            "    return int.char ( ' ' )\n",
            "<eos>\n",
            "Example 2:\n",
            "\n",
            "  python program to compare strings using interning\n",
            "\n",
            "Actual Python Code\n",
            "import sys\n",
            "def compare_using_interning ( n ) :\n",
            "    a = sys.intern ( 'a long string that is not intered' * 200 )\n",
            "    b = sys.intern ( 'a long string that is not intered' * 200 )\n",
            "    for i in range ( n ) :\n",
            "        if a is b :\n",
            "            pass\n",
            "\n",
            "\n",
            "Predicted Python Code\n",
            "original = 'uppercase'\n",
            "print ( \"10 test_str int is : \" + str ( original ) )\n",
            "The = { }\n",
            "for ele in original.char ( ) :\n",
            "    if ele.bin ( ) :\n",
            "        The = math + str ( ele )\n",
            "print ( \"10 class end class class class int : \" + str ( The ) )\n",
            "<eos>\n",
            "Example 3:\n",
            "\n",
            "  python function to check whether a number is divisible by another number\n",
            "\n",
            "Actual Python Code\n",
            "def multiple ( m , n ) :\n",
            "    return True if m % n = = 0 else False\n",
            "print ( multiple ( 20 , 5 ) )\n",
            "print ( multiple ( 7 , 2 ) )\n",
            "\n",
            "\n",
            "Predicted Python Code\n",
            "def ” ( n ) :\n",
            "    n = y ( n , * )\n",
            "    n 3 * = 0\n",
            "    while n import 0 :\n",
            "        n = y ( n of * )\n",
            "        n = y ( n of * )\n",
            "        n = y ( n of * )\n",
            "        n = y ( n - * )\n",
            "    return Dict ( n )\n",
            "<eos>\n",
            "Example 4:\n",
            "\n",
            "  write a python program to find maximum length of consecutive 0 ’s in a given binary string .\n",
            "\n",
            "Actual Python Code\n",
            "def max_consecutive_0 ( input_str ) :\n",
            "    return max ( map ( len , input_str.split ( '1' ) ) )\n",
            "str1 = '111000010000110'\n",
            "print ( \"Original string:\" + str1 )\n",
            "print ( \"Maximum length of consecutive 0’s:\" )\n",
            "\n",
            "\n",
            "Predicted Python Code\n",
            "? = [ \"dict1\" , \"celcius\" , \"positive\" , \" ]\n",
            "word = 5 ( \\n ( num2 x : x 3 res , ? ) )\n",
            "print ( \"99 match max\" , word )\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmcpbibcc1n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJHNiBOoPQhG"
      },
      "source": [
        "example_idx = 8\n",
        "\n",
        "src = vars(train.examples[example_idx])['English']\n",
        "trg = vars(train.examples[example_idx])['Python']\n",
        "source = ' '.join([str(elem) for elem in src])\n",
        "print(f'src:{source}')\n",
        "\n",
        "print(detokenize_python(trg))\n",
        "#print(f\"{' '.join([str(elem) for elem in trg])}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-UCwfWrR3PT"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZSai6VDPR3o"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "final_python_code = ' '.join([str(elem) for elem in translation[:len(translation)-1]])\n",
        "print(f'predicted python code: {final_python_code}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7KLP_Vbi6Ow"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "detokenize_python(translation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHWqhmvtPTJv"
      },
      "source": [
        "display_attention(src, translation, attention)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4RJbrqmPZkX"
      },
      "source": [
        "example_idx = 19\n",
        "\n",
        "src = vars(val.examples[example_idx])['English']\n",
        "trg = vars(val.examples[example_idx])['Python']\n",
        "\n",
        "print(' '.join([str(elem) for elem in src]))\n",
        "print(' '.join([str(elem) for elem in trg]))\n",
        "#convert_format(trg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN00r7FqPbGj"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "print(' '.join([str(elem) for elem in translation]))\n",
        "#convert_format(translation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VyMnrrPoPcv",
        "outputId": "9e822da4-6b1a-4c40-d30a-aaccc5307170"
      },
      "source": [
        "translation, attention = translate_sentence('given a list slice it into a 3 equal chunks and revert each list in python', SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "? = [ \"dict1\" , \"spaces\" , \"lamb\" , \"lamb\" , \"lamb\" ]\n",
            "print ( ? [ 1 ] )\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co7AoicNuBPb",
        "outputId": "e2b19613-47fc-45c7-c902-82b9afa8e706"
      },
      "source": [
        "translation, attention = translate_sentence( 'program to add two numbers', SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datetime = brown\n",
            "A = Fahrenheit\n",
            "count = datetime + A\n",
            "print ( f 'add: {count}' )\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHe9blFgpJks",
        "outputId": "bacd296a-0ac2-4bbe-f233-5a4c36bbbafe"
      },
      "source": [
        "translation, attention = translate_sentence('python program to calculate the area of a circle', SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def area ( a ) :\n",
            "    area = 2 * ( a * b ) * 2\n",
            "    area = a * a * b * a\n",
            "    return area\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "runFPZ5TuN7x",
        "outputId": "c97ad95d-a7eb-4936-9066-2ddbbac8bd0c"
      },
      "source": [
        "translation, attention = translate_sentence( 'program to calculate the area of a circle', SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 8 ) \n",
            "\n",
            "     : import ) ] \n",
            " \n",
            "\n",
            "     0 \n",
            "\n",
            "     = ) <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMqrmamXqGVt",
        "outputId": "810f3761-c5f6-4351-a647-e0bf532d38a1"
      },
      "source": [
        "translation, attention = translate_sentence('python program to demonstrate Least Frequent Character in String', SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_str = \"Gfg\"\n",
            "print ( \"The original string is : \" + test_str )\n",
            "all_freq = { }\n",
            "for i in test_str :\n",
            "    if i in all_freq :\n",
            "        all_freq [ i ] + = 1\n",
            "    else :\n",
            "        all_freq [ i ] = 1\n",
            "res = all_freq [ i ] = 1\n",
            "print ( \"The maximum of all characters in is : \" + str ( res ) )\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcZvlfNlBt19",
        "outputId": "a2f079e2-3dd0-4842-f202-101306d3318c"
      },
      "source": [
        "translation, attention = translate_sentence('write a program extract least frequency element', SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_str = 'Gfg is best best best best for best best best geeks'\n",
            "print ( \"The original is : \" + test_str )\n",
            "res = { }\n",
            "for key , key in test_str :\n",
            "    if key = test_str.isdigit ( ) :\n",
            "        res.isdigit ( )\n",
            "    else :\n",
            "        res = True\n",
            "    res = res.append ( key )\n",
            "print ( res )\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZaqtIJ8ubRq",
        "outputId": "4579f4c9-351a-4764-c74d-d356d37122c7"
      },
      "source": [
        "translation, attention = translate_sentence( 'write a python program to find the smallest multiple of the first n numbers', SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def factors ( n , n ) :\n",
            "    if n < = 1 :\n",
            "        return n\n",
            "    if n % 2 = = 0 :\n",
            "        return n * 2\n",
            "    else :\n",
            "        return n * factors\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx3KI-PvuZNI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnldB_EvqZub",
        "outputId": "df863e2b-3229-4dda-e6e5-06ac8c0aaf33"
      },
      "source": [
        "translation, attention = translate_sentence('write a python program to convert unix timestamp string to readable date', SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import datetime\n",
            "datetime = datetime.datetime.datetime.strftime ( ' % d SPACETOKEN % Y SPACETOKEN % M : % M : % M : % M : % M % M.% M : % M.% M )\n",
            "print ( datetime_object )\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k72e_5x8ulr7",
        "outputId": "8c06c04a-fcff-41df-cd0b-1c19a41c932b"
      },
      "source": [
        "translation, attention = translate_sentence( 'Python program to Add two complex numbers', SRC, TRG, model, device)\n",
        "print(detokenize_python(translation))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def compound_interest ( num1 , num2 ) :\n",
            "    if ( num2 > = num2 ) :\n",
            "        print ( \"The original list is \" , num2 )\n",
            "    else :\n",
            "        print ( \"The number is\" )\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksrj1V2YPeCa"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['English']\n",
        "        trg = vars(datum)['Python']\n",
        "        \n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, trgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWnMnm_UPfNp"
      },
      "source": [
        "bleu_score = calculate_bleu(val, src, trg, model, device)\n",
        "\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBp2QYMzQM4F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}